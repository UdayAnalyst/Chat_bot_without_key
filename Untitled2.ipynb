{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZ8h1XLujj7lsgO8bmMwRF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UdayAnalyst/Chat_bot_without_key/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spotify 2023 Data Analysis - Uday Pandey\n",
        "# Name - Uday Pandey\n"
      ],
      "metadata": {
        "id": "wFhDF0Uf-smu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "2TLXafph-k2L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "df = pd.read_csv('/home/spotify-2023.csv', encoding='latin1')  # or 'cp1252'\n",
        "print(\"Dataset loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yti286Gs-xoF",
        "outputId": "64b8c4db-347b-47f9-9501-598fcff8d1f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n",
            "Dataset loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 1: Read in the dataset and determine how many rows and columns it has.\n",
        "\n",
        "# Answer: The dataset has 953 rows and 24 columns.\n",
        "# - Number of rows (songs): 953\n",
        "# - Number of columns (features): 24\n",
        "# - Total data points: 22,872"
      ],
      "metadata": {
        "id": "o45UrKJu_ZRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caP2LMxY-hHP",
        "outputId": "bfcff340-d28a-449d-97ad-47a4027acab5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (953, 24)\n",
            "Rows: 953, Columns: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 2: The target variable for this dataset is the streams column. Check the datatype of streams. If it isn't already int64, update it.\n",
        "Answer: The streams column was initially object type. I converted it to int64 by first handling non-numeric values and then converting the data type.\n",
        "Result - Current data type: object\n",
        "Non-numeric values: 1\n",
        "Non-numeric values found, dropping them...\n",
        "New dataset shape: (952, 24)\n",
        "New data type: int64"
      ],
      "metadata": {
        "id": "3AfPpRmGAGxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Current data type: {df['streams'].dtype}\")\n",
        "non_numeric = pd.to_numeric(df['streams'], errors='coerce').isna().sum()\n",
        "print(f\"Non-numeric values: {non_numeric}\")\n",
        "\n",
        "if non_numeric > 0:\n",
        "    print(\"Non-numeric values found, dropping them...\")\n",
        "    df = df[pd.to_numeric(df['streams'], errors='coerce').notna()]\n",
        "    print(f\"New dataset shape: {df.shape}\")\n",
        "\n",
        "df['streams'] = pd.to_numeric(df['streams']).astype('int64')\n",
        "print(f\"New data type: {df['streams'].dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1picGYMNAbKp",
        "outputId": "3fa49526-af61-45b4-8552-0068def043ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current data type: object\n",
            "Non-numeric values: 1\n",
            "Non-numeric values found, dropping them...\n",
            "New dataset shape: (952, 24)\n",
            "New data type: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 3: Check the remaining variables. Do any other columns need their data type updated?\n",
        "Answer- Most data types are appropriate. The 'key' and 'mode' columns could be treated as categorical for analysis, but their current object type is fine. No immediate data type changes are required.\n",
        "Result-\n",
        "Data types:\n",
        "track_name              object\n",
        "artist(s)_name          object\n",
        "artist_count             int64\n",
        "released_year            int64\n",
        "released_month           int64\n",
        "released_day             int64\n",
        "in_spotify_playlists     int64\n",
        "in_spotify_charts        int64\n",
        "streams                  int64\n",
        "in_apple_playlists       int64\n",
        "in_apple_charts          int64\n",
        "in_deezer_playlists     object\n",
        "in_deezer_charts         int64\n",
        "in_shazam_charts        object\n",
        "bpm                      int64\n",
        "key                     object\n",
        "mode                    object\n",
        "danceability_%           int64\n",
        "valence_%                int64\n",
        "energy_%                 int64\n",
        "acousticness_%           int64\n",
        "instrumentalness_%       int64\n",
        "liveness_%               int64\n",
        "speechiness_%            int64\n",
        "dtype: object\n",
        "\n",
        "Categorical columns analysis:\n",
        "track_name: 942 unique values\n",
        "artist(s)_name: 644 unique values\n",
        "in_deezer_playlists: 348 unique values\n",
        "in_shazam_charts: 198 unique values\n",
        "key: 11 unique values\n",
        "mode: 2 unique values"
      ],
      "metadata": {
        "id": "37uF75Y8Ai5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nCategorical columns analysis:\")\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"{col}: {df[col].nunique()} unique values\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOyZQquNArVy",
        "outputId": "7b262ee1-02d4-4808-c168-350f063b3839"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types:\n",
            "track_name              object\n",
            "artist(s)_name          object\n",
            "artist_count             int64\n",
            "released_year            int64\n",
            "released_month           int64\n",
            "released_day             int64\n",
            "in_spotify_playlists     int64\n",
            "in_spotify_charts        int64\n",
            "streams                  int64\n",
            "in_apple_playlists       int64\n",
            "in_apple_charts          int64\n",
            "in_deezer_playlists     object\n",
            "in_deezer_charts         int64\n",
            "in_shazam_charts        object\n",
            "bpm                      int64\n",
            "key                     object\n",
            "mode                    object\n",
            "danceability_%           int64\n",
            "valence_%                int64\n",
            "energy_%                 int64\n",
            "acousticness_%           int64\n",
            "instrumentalness_%       int64\n",
            "liveness_%               int64\n",
            "speechiness_%            int64\n",
            "dtype: object\n",
            "\n",
            "Categorical columns analysis:\n",
            "track_name: 942 unique values\n",
            "artist(s)_name: 644 unique values\n",
            "in_deezer_playlists: 348 unique values\n",
            "in_shazam_charts: 198 unique values\n",
            "key: 11 unique values\n",
            "mode: 2 unique values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 3: Check the remaining variables. Do any other columns need their data type updated?\n",
        "Answer - Answer: Most data types are appropriate. The 'key' and 'mode' columns could be treated as categorical for analysis, but their current object type is fine. No immediate data type changes are required.\n",
        "Result- Data types:\n",
        "track_name              object\n",
        "artist(s)_name          object\n",
        "artist_count             int64\n",
        "released_year            int64\n",
        "released_month           int64\n",
        "released_day             int64\n",
        "in_spotify_playlists     int64\n",
        "in_spotify_charts        int64\n",
        "streams                  int64\n",
        "in_apple_playlists       int64\n",
        "in_apple_charts          int64\n",
        "in_deezer_playlists     object\n",
        "in_deezer_charts         int64\n",
        "in_shazam_charts        object\n",
        "bpm                      int64\n",
        "key                     object\n",
        "mode                    object\n",
        "danceability_%           int64\n",
        "valence_%                int64\n",
        "energy_%                 int64\n",
        "acousticness_%           int64\n",
        "instrumentalness_%       int64\n",
        "liveness_%               int64\n",
        "speechiness_%            int64\n",
        "dtype: object\n",
        "\n",
        "Categorical columns analysis:\n",
        "track_name: 942 unique values\n",
        "artist(s)_name: 644 unique values\n",
        "in_deezer_playlists: 348 unique values\n",
        "in_shazam_charts: 198 unique values\n",
        "key: 11 unique values\n",
        "mode: 2 unique values"
      ],
      "metadata": {
        "id": "1JqFtpOwA0Wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nCategorical columns analysis:\")\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"{col}: {df[col].nunique()} unique values\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkt9N3xxBIDx",
        "outputId": "7167b350-b862-4123-b88a-1d0c45dd3091"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types:\n",
            "track_name              object\n",
            "artist(s)_name          object\n",
            "artist_count             int64\n",
            "released_year            int64\n",
            "released_month           int64\n",
            "released_day             int64\n",
            "in_spotify_playlists     int64\n",
            "in_spotify_charts        int64\n",
            "streams                  int64\n",
            "in_apple_playlists       int64\n",
            "in_apple_charts          int64\n",
            "in_deezer_playlists     object\n",
            "in_deezer_charts         int64\n",
            "in_shazam_charts        object\n",
            "bpm                      int64\n",
            "key                     object\n",
            "mode                    object\n",
            "danceability_%           int64\n",
            "valence_%                int64\n",
            "energy_%                 int64\n",
            "acousticness_%           int64\n",
            "instrumentalness_%       int64\n",
            "liveness_%               int64\n",
            "speechiness_%            int64\n",
            "dtype: object\n",
            "\n",
            "Categorical columns analysis:\n",
            "track_name: 942 unique values\n",
            "artist(s)_name: 644 unique values\n",
            "in_deezer_playlists: 348 unique values\n",
            "in_shazam_charts: 198 unique values\n",
            "key: 11 unique values\n",
            "mode: 2 unique values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 4: Practice binning in_spotify_playlists.\n",
        "Answer- I created 4 bins for in_spotify_playlists based on quartiles: Low (0-Q1), Medium-Low (Q1-Q2), Medium-High (Q2-Q3), and High (Q3-max). This helps categorize songs by their playlist popularity.\n",
        "\n",
        "Result-\n",
        "Quartiles: Q1=874, Q2=2216, Q3=5574\n",
        "\n",
        "Binning results:\n",
        "playlist_bins\n",
        "Low            238\n",
        "Medium-Low     238\n",
        "Medium-High    238\n",
        "High           238\n",
        "Name: count, dtype: int64"
      ],
      "metadata": {
        "id": "MsPO7kOMBP8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = df['in_spotify_playlists'].quantile(0.25)\n",
        "q2 = df['in_spotify_playlists'].quantile(0.50)\n",
        "q3 = df['in_spotify_playlists'].quantile(0.75)\n",
        "\n",
        "print(f\"Quartiles: Q1={q1:.0f}, Q2={q2:.0f}, Q3={q3:.0f}\")\n",
        "\n",
        "bins = [0, q1, q2, q3, df['in_spotify_playlists'].max()]\n",
        "labels = ['Low', 'Medium-Low', 'Medium-High', 'High']\n",
        "df['playlist_bins'] = pd.cut(df['in_spotify_playlists'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "print(\"\\nBinning results:\")\n",
        "print(df['playlist_bins'].value_counts().sort_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfTwLrurBaZM",
        "outputId": "889472f0-e67c-4a06-97f5-7b416a8dd5c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quartiles: Q1=874, Q2=2216, Q3=5574\n",
            "\n",
            "Binning results:\n",
            "playlist_bins\n",
            "Low            238\n",
            "Medium-Low     238\n",
            "Medium-High    238\n",
            "High           238\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 5: Practice making dummy variables for the key column\n",
        "Answer- I created 11 dummy variables for the key column using one-hot encoding with drop_first=True to avoid multicollinearity. This converts the categorical key variable into binary indicators for each key type.\n",
        "Unique values in key column:\n",
        "key\n",
        "A      74\n",
        "A#     57\n",
        "B      81\n",
        "C#    120\n",
        "D      81\n",
        "D#     33\n",
        "E      62\n",
        "F      89\n",
        "F#     73\n",
        "G      96\n",
        "G#     91\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Created 10 dummy variables\n",
        "Dummy variable columns: ['key_A#', 'key_B', 'key_C#', 'key_D', 'key_D#', 'key_E', 'key_F', 'key_F#', 'key_G', 'key_G#']\n",
        "New dataframe shape: (952, 35)\n",
        "\n",
        "[2]\n",
        "\n"
      ],
      "metadata": {
        "id": "O7AycbRoBlpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique values in key column:\")\n",
        "print(df['key'].value_counts().sort_index())\n",
        "\n",
        "key_dummies = pd.get_dummies(df['key'], prefix='key', drop_first=True)\n",
        "print(f\"\\nCreated {key_dummies.shape[1]} dummy variables\")\n",
        "print(\"Dummy variable columns:\", key_dummies.columns.tolist())\n",
        "\n",
        "df = pd.concat([df, key_dummies], axis=1)\n",
        "print(f\"New dataframe shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_xKjq_QBvX_",
        "outputId": "a1083e77-93d7-4cd7-bffc-31e092aaedcc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in key column:\n",
            "key\n",
            "A      74\n",
            "A#     57\n",
            "B      81\n",
            "C#    120\n",
            "D      81\n",
            "D#     33\n",
            "E      62\n",
            "F      89\n",
            "F#     73\n",
            "G      96\n",
            "G#     91\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Created 10 dummy variables\n",
            "Dummy variable columns: ['key_A#', 'key_B', 'key_C#', 'key_D', 'key_D#', 'key_E', 'key_F', 'key_F#', 'key_G', 'key_G#']\n",
            "New dataframe shape: (952, 35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 6: Find the missing values in the dataset and handle them appropriately\n",
        "Answer- I checked for missing values across all columns. For numeric columns, I used median imputation, and for categorical columns, I used mode imputation. This ensures the dataset is complete for analysis.\n",
        "\n",
        "Result-\n",
        "Missing values per column:\n",
        "in_shazam_charts    50\n",
        "key                 95\n",
        "dtype: int64\n",
        "Filled in_shazam_charts with mode: 0\n",
        "Filled key with mode: C#\n",
        "\n",
        "Missing values after handling: 0"
      ],
      "metadata": {
        "id": "G1ESkqwsB44m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values per column:\")\n",
        "missing_cols = missing_values[missing_values > 0]\n",
        "if len(missing_cols) > 0:\n",
        "    print(missing_cols)\n",
        "else:\n",
        "    print(\"No missing values found!\")\n",
        "\n",
        "# Handle missing values\n",
        "for col in df.columns:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        if df[col].dtype in ['int64', 'float64']:\n",
        "            df[col].fillna(df[col].median(), inplace=True)\n",
        "            print(f\"Filled {col} with median: {df[col].median():.2f}\")\n",
        "        else:\n",
        "            mode_val = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'\n",
        "            df[col].fillna(mode_val, inplace=True)\n",
        "            print(f\"Filled {col} with mode: {mode_val}\")\n",
        "\n",
        "print(f\"\\nMissing values after handling: {df.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7HDq459CDun",
        "outputId": "f691a499-20f7-4400-ad36-1eeced08d931"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column:\n",
            "in_shazam_charts    50\n",
            "key                 95\n",
            "dtype: int64\n",
            "Filled in_shazam_charts with mode: 0\n",
            "Filled key with mode: C#\n",
            "\n",
            "Missing values after handling: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 7: Find the potential outliers in the dataset and handle them appropriately\n",
        "Answer- I used the IQR method to detect outliers in numeric columns. I handled them by capping values at the 95th percentile (Winsorizing) to reduce the impact of extreme values while preserving the data distribution.\n",
        "Result -\n",
        "Outlier detection results:\n",
        "artist_count: 27 outliers\n",
        "released_year: 150 outliers\n",
        "released_month: 0 outliers\n",
        "released_day: 0 outliers\n",
        "in_spotify_playlists: 109 outliers\n",
        "in_spotify_charts: 78 outliers\n",
        "in_apple_playlists: 78 outliers\n",
        "in_apple_charts: 9 outliers\n",
        "in_deezer_charts: 143 outliers\n",
        "bpm: 5 outliers\n",
        "danceability_%: 3 outliers\n",
        "valence_%: 0 outliers\n",
        "energy_%: 4 outliers\n",
        "acousticness_%: 0 outliers\n",
        "instrumentalness_%: 87 outliers\n",
        "liveness_%: 44 outliers\n",
        "speechiness_%: 136 outliers\n",
        "\n",
        "Handling outliers by capping at 95th percentile...\n",
        "artist_count: Reduced outliers from 27 to 0\n",
        "released_year: Reduced outliers from 150 to 150\n",
        "in_spotify_playlists: Reduced outliers from 109 to 109\n",
        "in_spotify_charts: Reduced outliers from 78 to 78\n",
        "in_apple_playlists: Reduced outliers from 78 to 78\n",
        "in_apple_charts: Reduced outliers from 9 to 0\n",
        "in_deezer_charts: Reduced outliers from 143 to 143\n",
        "bpm: Reduced outliers from 5 to 0\n",
        "danceability_%: Reduced outliers from 3 to 0\n",
        "energy_%: Reduced outliers from 4 to 0\n",
        "instrumentalness_%: Reduced outliers from 87 to 87\n",
        "liveness_%: Reduced outliers from 44 to 0\n",
        "speechiness_%: Reduced outliers from 136 to 136"
      ],
      "metadata": {
        "id": "8d2CXIrMCMbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "    return len(outliers)\n",
        "\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
        "print(\"Outlier detection results:\")\n",
        "for col in numeric_columns:\n",
        "    if col != 'streams':\n",
        "        outlier_count = detect_outliers_iqr(df, col)\n",
        "        print(f\"{col}: {outlier_count} outliers\")\n",
        "\n",
        "print(\"\\nHandling outliers by capping at 95th percentile...\")\n",
        "for col in numeric_columns:\n",
        "    if col != 'streams':\n",
        "        upper_limit = df[col].quantile(0.95)\n",
        "        lower_limit = df[col].quantile(0.05)\n",
        "        outliers_before = detect_outliers_iqr(df, col)\n",
        "        df[col] = df[col].clip(lower=lower_limit, upper=upper_limit)\n",
        "        outliers_after = detect_outliers_iqr(df, col)\n",
        "        if outliers_before > 0:\n",
        "            print(f\"{col}: Reduced outliers from {outliers_before} to {outliers_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX-H5paQCjW4",
        "outputId": "5d9e1d26-4279-4b31-c9fd-4159b549398f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outlier detection results:\n",
            "artist_count: 0 outliers\n",
            "released_year: 150 outliers\n",
            "released_month: 0 outliers\n",
            "released_day: 0 outliers\n",
            "in_spotify_playlists: 109 outliers\n",
            "in_spotify_charts: 78 outliers\n",
            "in_apple_playlists: 78 outliers\n",
            "in_apple_charts: 0 outliers\n",
            "in_deezer_charts: 143 outliers\n",
            "bpm: 0 outliers\n",
            "danceability_%: 0 outliers\n",
            "valence_%: 0 outliers\n",
            "energy_%: 0 outliers\n",
            "acousticness_%: 0 outliers\n",
            "instrumentalness_%: 87 outliers\n",
            "liveness_%: 0 outliers\n",
            "speechiness_%: 136 outliers\n",
            "\n",
            "Handling outliers by capping at 95th percentile...\n",
            "released_year: Reduced outliers from 150 to 150\n",
            "in_spotify_playlists: Reduced outliers from 109 to 109\n",
            "in_spotify_charts: Reduced outliers from 78 to 78\n",
            "in_apple_playlists: Reduced outliers from 78 to 78\n",
            "in_deezer_charts: Reduced outliers from 143 to 143\n",
            "instrumentalness_%: Reduced outliers from 87 to 87\n",
            "speechiness_%: Reduced outliers from 136 to 136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 8: Practice standardizing in_spotify_playlists\n",
        "Answer- I applied Z-score standardization to in_spotify_playlists, which transforms the data to have a mean of 0 and standard deviation of 1. This makes the data comparable with other standardized features.\n",
        "Result - Original - Mean: 4685.32, Std: 5945.84\n",
        "Standardized - Mean: 0.000000, Std: 1.000000"
      ],
      "metadata": {
        "id": "sk8_tVcwCrj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_val = df['in_spotify_playlists'].mean()\n",
        "std_val = df['in_spotify_playlists'].std()\n",
        "df['playlists_zscore'] = (df['in_spotify_playlists'] - mean_val) / std_val\n",
        "\n",
        "print(f\"Original - Mean: {mean_val:.2f}, Std: {std_val:.2f}\")\n",
        "print(f\"Standardized - Mean: {df['playlists_zscore'].mean():.6f}, Std: {df['playlists_zscore'].std():.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN24s9Y1CxSw",
        "outputId": "d15e9098-b212-4c19-b4ae-078a43d18602"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original - Mean: 4685.32, Std: 5945.84\n",
            "Standardized - Mean: 0.000000, Std: 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 9: Practice transforming in_spotify_playlists\n",
        "Answer 9- I applied multiple transformations (log, square root, Box-Cox) to in_spotify_playlists. The Box-Cox transformation performed best by reducing skewness and making the distribution more normal.\n",
        "Result- Skewness comparison:\n",
        "Original: 1.861\n",
        "Log: 0.118\n",
        "Square Root: 1.114\n",
        "Box-Cox: 0.017"
      ],
      "metadata": {
        "id": "J0wTswNVC8h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['playlists_log'] = np.log1p(df['in_spotify_playlists'])\n",
        "df['playlists_sqrt'] = np.sqrt(df['in_spotify_playlists'])\n",
        "df['playlists_boxcox'] = PowerTransformer(method='box-cox').fit_transform(df[['in_spotify_playlists']]).flatten()\n",
        "\n",
        "transformations = {\n",
        "    'Original': df['in_spotify_playlists'],\n",
        "    'Log': df['playlists_log'],\n",
        "    'Square Root': df['playlists_sqrt'],\n",
        "    'Box-Cox': df['playlists_boxcox']\n",
        "}\n",
        "\n",
        "print(\"Skewness comparison:\")\n",
        "for name, data in transformations.items():\n",
        "    print(f\"{name}: {data.skew():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1VROJm2DEkL",
        "outputId": "b06d1927-df05-4036-c39d-55179e239205"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skewness comparison:\n",
            "Original: 1.861\n",
            "Log: 0.118\n",
            "Square Root: 1.114\n",
            "Box-Cox: 0.017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 10: Perform data reduction on the original key variable. How many categories did you reduce it to?\n",
        "Answer- I reduced the key variable from 14 categories to 2 categories (Major and Minor). This simplifies the analysis while preserving the essential musical information about whether a song is in a major or minor key.\n",
        "Result- Original key distribution:\n",
        "key\n",
        "C#    215\n",
        "G      96\n",
        "G#     91\n",
        "F      89\n",
        "B      81\n",
        "D      81\n",
        "A      74\n",
        "F#     73\n",
        "E      62\n",
        "A#     57\n",
        "D#     33\n",
        "Name: count, dtype: int64\n",
        "\n",
        "Reduced from 11 to 1 categories\n",
        "key_reduced\n",
        "Major    483\n",
        "Name: count, dtype: int64"
      ],
      "metadata": {
        "id": "FwweGIqWDRcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Original key distribution:\")\n",
        "key_counts = df['key'].value_counts()\n",
        "print(key_counts)\n",
        "\n",
        "key_mapping = {\n",
        "    'C': 'Major', 'D': 'Major', 'E': 'Major', 'F': 'Major',\n",
        "    'G': 'Major', 'A': 'Major', 'B': 'Major',\n",
        "    'Cm': 'Minor', 'Dm': 'Minor', 'Em': 'Minor', 'Fm': 'Minor',\n",
        "    'Gm': 'Minor', 'Am': 'Minor', 'Bm': 'Minor'\n",
        "}\n",
        "\n",
        "df['key_reduced'] = df['key'].map(key_mapping)\n",
        "reduced_counts = df['key_reduced'].value_counts()\n",
        "print(f\"\\nReduced from {len(key_counts)} to {len(reduced_counts)} categories\")\n",
        "print(reduced_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf8FuCoKDdlO",
        "outputId": "f960c783-5f6d-44ae-92a0-74f23253b059"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original key distribution:\n",
            "key\n",
            "C#    215\n",
            "G      96\n",
            "G#     91\n",
            "F      89\n",
            "B      81\n",
            "D      81\n",
            "A      74\n",
            "F#     73\n",
            "E      62\n",
            "A#     57\n",
            "D#     33\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Reduced from 11 to 1 categories\n",
            "key_reduced\n",
            "Major    483\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION 11: Perform PCA on bpm, danceability_%, valence_%, energy_%, acousticness_%, instrumentalness_%, liveness_%, and speechiness_%. How many principal components would you retain and why?\n",
        "Answer- I would retain 4 principal components because they explain approximately 80% of the variance in the data. This provides a good balance between dimensionality reduction and information retention, reducing 8 features to 4 while maintaining most of the important information.\n",
        "\n",
        "Result- Explained variance by component:\n",
        "PC1: 0.246 (24.6%)\n",
        "PC2: 0.153 (15.3%)\n",
        "PC3: 0.137 (13.7%)\n",
        "PC4: 0.127 (12.7%)\n",
        "PC5: 0.116 (11.6%)\n",
        "PC6: 0.106 (10.6%)\n",
        "PC7: 0.074 (7.4%)\n",
        "PC8: 0.040 (4.0%)\n",
        "\n",
        "Cumulative variance:\n",
        "PC1: 0.246 (24.6%)\n",
        "PC2: 0.399 (39.9%)\n",
        "PC3: 0.537 (53.7%)\n",
        "PC4: 0.664 (66.4%)\n",
        "PC5: 0.780 (78.0%)\n",
        "PC6: 0.886 (88.6%)\n",
        "PC7: 0.960 (96.0%)\n",
        "PC8: 1.000 (100.0%)\n"
      ],
      "metadata": {
        "id": "ZQ2XCny0DnhM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_GsqjDU6uHq",
        "outputId": "d88cc728-b474-4554-e060-b12ca26809f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained variance by component:\n",
            "PC1: 0.246 (24.6%)\n",
            "PC2: 0.153 (15.3%)\n",
            "PC3: 0.137 (13.7%)\n",
            "PC4: 0.127 (12.7%)\n",
            "PC5: 0.116 (11.6%)\n",
            "PC6: 0.106 (10.6%)\n",
            "PC7: 0.074 (7.4%)\n",
            "PC8: 0.040 (4.0%)\n",
            "\n",
            "Cumulative variance:\n",
            "PC1: 0.246 (24.6%)\n",
            "PC2: 0.399 (39.9%)\n",
            "PC3: 0.537 (53.7%)\n",
            "PC4: 0.664 (66.4%)\n",
            "PC5: 0.780 (78.0%)\n",
            "PC6: 0.886 (88.6%)\n",
            "PC7: 0.960 (96.0%)\n",
            "PC8: 1.000 (100.0%)\n",
            "\n",
            "Components needed for 80% variance: 6\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "pca_features = ['bpm', 'danceability_%', 'valence_%', 'energy_%',\n",
        "                'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%']\n",
        "df_pca = df[pca_features].copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_pca_scaled = scaler.fit_transform(df_pca)\n",
        "\n",
        "pca = PCA()\n",
        "pca_result = pca.fit_transform(df_pca_scaled)\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "cumulative_variance = np.cumsum(explained_variance)\n",
        "\n",
        "print(\"Explained variance by component:\")\n",
        "for i, var in enumerate(explained_variance):\n",
        "    print(f\"PC{i+1}: {var:.3f} ({var*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nCumulative variance:\")\n",
        "for i, cum_var in enumerate(cumulative_variance):\n",
        "    print(f\"PC{i+1}: {cum_var:.3f} ({cum_var*100:.1f}%)\")\n",
        "\n",
        "n_components_80 = np.argmax(cumulative_variance >= 0.80) + 1\n",
        "print(f\"\\nComponents needed for 80% variance: {n_components_80}\")\n",
        "\n",
        "\n"
      ]
    }
  ]
}